1. 感知机算法实质上就是一个sigmoid函数，即一个二分类模型。f(x) = sign(w.x+b)
2. k临近算法实质就是一个少数服从多数的的投票模型，适用于多分类情况，当前和目标距离最近的k个邻居中，大部分的标签
3. 朴素贝叶斯认为所有特征都是独立的，一个样本出现的概率是使其所有特征出现概率的联乘。
4. 决策树算法的基本原理是，每次从特征集中选择一个对训练集的信息增益最大的特征，然后划分训练集，形成各个子集，之后再分别以各个子集作为训练集，以剩余特征作为特征集，重复之前的步骤。
5. logistic回归，可以看作是最大熵模型的一种特例,是一个二分类问题，把似然函数转化为对数似然函数，我们的目的是将该函数最大化，其实实质和感知机模型没什么差异。
6. 熵是随机变量不确定性的度量，值越大，不确定性就越大。熵的定义 H(X)=-求和p(x)logp(x) 在满足约束条件的模型集合中选取熵最大的模型。拉格朗日乘子，就是将带约束极值问题，转化为无约束极值问题进行求解。
经验分布是指通过训练数据统计得到的分布 p(y|x) = e^w-1 . e^wi.fi(x,y) 使用的是条件熵
7. 支持向量机原理在于找一个超平面，这个超平面可以正确划分训练数据集，并且几何间距最大
8. AdaBoost：通过每次降低个体学习器的分类误差，加大效果好的个体学习器的重要性，得到最终的集成学习器。
9. 马尔可夫模型：应用观测序列来帮助推到状态转移

